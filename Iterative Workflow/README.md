# ğŸ” Iterative Workflow

> Iterative workflows use **loops** to repeat a set of nodes until a condition is met. Unlike sequential workflows where nodes run once in order, iterative workflows use `add_conditional_edges()` to decide whether to **loop back** to a previous node or **exit** to the next step.

---

## ğŸ“ Files

| File | Description |
|------|-------------|
| `Iterative Workflow.py` | Simple Counter â€” basic loop that counts up to a target |
| `Iterative Workflow 1.py` | AI Tweet Generator â€” iterative generate â†’ evaluate â†’ optimize loop with LLM |

---

## ğŸ“„ File 1: `Iterative Workflow.py` â€” Simple Counter

### What We Did
- Built the **simplest possible iterative workflow** â€” a counter that loops until it reaches a target number.
- Defined a `CounterState` with:
  - `count: int` â€” the current count
  - `target: int` â€” the number to stop at
- **Two nodes**:
  - `add_one` â†’ Increments `count` by 1 each iteration.
  - `done` â†’ Prints the final count when the loop ends.
- **One routing function**:
  - `check_count` â†’ Decides whether to loop back to `add_one` or move to `done`.
- Used `add_conditional_edges()` to create the loop â€” this is the **core mechanism** for iterative workflows in LangGraph.

### Graph Flow
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ START â”‚â”€â”€â”€â”€â”€â†’â”‚ add_one â”‚â”€â”€â”€â”€â”€â†’â”‚ check_count â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†‘                    â”‚
                   â”‚    count < target  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                              count >= target
                                        â”‚
                                        â†“
                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”
                                   â”‚  done  â”‚â”€â”€â”€â”€â”€â†’â”‚ END â”‚
                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”˜
```

### Sample Output
```
ğŸ¯ Enter a target number to count to: 5
==============================
ğŸ¯ Counting to 5
==============================
ğŸ”„ Count: 1
ğŸ”„ Count: 2
ğŸ”„ Count: 3
ğŸ”„ Count: 4
ğŸ”„ Count: 5

âœ… Done! Final count: 5

ğŸ“Š Final State: {'count': 5, 'target': 5}
```

---

## ğŸ“„ File 2: `Iterative Workflow 1.py` â€” AI Tweet Generator & Evaluator

### What We Did
- Built an **iterative LLM-powered pipeline** that generates a tweet, evaluates it, and optimizes it in a loop until the tweet is approved or the max iteration limit is reached.
- Used **Groq LLM** (`llama-3.3-70b-versatile`) for both generation and evaluation.
- Used **Pydantic structured output** (`Evaluation` model) to force the evaluator LLM to return a typed response with `evaluation` and `feedback` fields.
- Defined `PostState` (TypedDict) with:
  - `topic` â€” The tweet topic
  - `tweet` â€” The current tweet draft
  - `evaluation` â€” `"approved"` or `"needs_improvement"`
  - `feedback` â€” Evaluator's feedback on the tweet
  - `iteration` / `max_iterations` â€” Loop control
  - `tweet_history: Annotated[list[str], operator.add]` â€” All tweet versions (appended via reducer)
  - `feedback_history: Annotated[list[str], operator.add]` â€” All feedback entries (appended via reducer)
- **Three nodes**:
  - `generate_tweet` â†’ Writes an original, humorous tweet on the given topic.
  - `evaluate_tweet` â†’ A ruthless Twitter critic that scores the tweet on originality, humor, punchiness, virality, and format. Auto-rejects Q&A jokes, setup-punchline format, and tweets over 280 characters.
  - `optimize_tweet` â†’ Rewrites the tweet based on the evaluator's feedback.
- **One routing function**:
  - `route_evaluation` â†’ If `"approved"` or max iterations reached â†’ END. Otherwise â†’ loop back to `optimize_tweet`.

### Graph Flow
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ START â”‚â”€â”€â”€â”€â”€â†’â”‚ generate_tweet â”‚â”€â”€â”€â”€â”€â†’â”‚ evaluate_tweet â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                   â”‚                     â”‚
                              "approved"          "needs_improvement"
                            OR max iters              â”‚
                                   â”‚                  â†“
                                   â†“          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”Œâ”€â”€â”€â”€â”€â”        â”‚ optimize_tweet â”‚
                               â”‚ END â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â””â”€â”€â”€â”€â”€â”˜                â”‚
                                                      â”‚
                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â†“
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚ evaluate_tweet â”‚ (loop back)
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Concepts Used

| Concept | How It's Used |
|---------|---------------|
| **Structured Output** | `llm.with_structured_output(schema=Evaluation)` forces the evaluator to return typed `evaluation` + `feedback` |
| **Pydantic BaseModel** | `Evaluation` model with `Literal["approved", "needs_improvement"]` ensures valid responses |
| **`operator.add` reducer** | `tweet_history` and `feedback_history` append across iterations instead of overwriting |
| **Conditional Edges** | `route_evaluation` decides to loop or exit based on evaluation result and iteration count |
| **Max Iteration Guard** | Prevents infinite loops â€” stops after `max_iterations` even if not approved |

### Sample Output
```
==================================================
FINAL TWEET: <optimized tweet text>
==================================================
EVALUATION: APPROVED
FEEDBACK: <evaluator's final feedback>
ITERATIONS: 2
--------------------------------------------------
TWEET HISTORY:
  1. <first draft>
  2. <optimized version>
--------------------------------------------------
FEEDBACK HISTORY:
  1. <first round feedback>
  2. <second round feedback>
==================================================
```

---

## ğŸ”‘ Key Concepts Learned

| Concept | What It Means |
|---------|---------------|
| **Iterative Workflow** | A workflow where nodes can loop back to previous nodes until a condition is met |
| **`add_conditional_edges()`** | The LangGraph method that enables branching and looping based on a routing function |
| **Routing Function** | A plain Python function that returns the name of the next node to execute |
| **Loop Guard** | Using a counter (`iteration` / `max_iterations`) to prevent infinite loops |
| **`operator.add` reducer** | Appends list values across iterations instead of overwriting â€” essential for tracking history |
| **Structured Output** | Using Pydantic `BaseModel` + `with_structured_output()` to get typed LLM responses |

---

## â–¶ï¸ How to Run

```bash
# Activate virtual environment
.\langvenv\Scripts\Activate.ps1

# Run the simple counter
python "Iterative Workflow/Iterative Workflow.py"

# Run the AI tweet generator
python "Iterative Workflow/Iterative Workflow 1.py"
```

> **Note:** For `Iterative Workflow 1.py`, make sure your `.env` file has the `GROQ_API_KEY` set.
