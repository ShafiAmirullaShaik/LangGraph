# üß† LangGraph ‚Äî Learning Project

> A hands-on learning project for building **intelligent, stateful, multi-step LLM workflows** using [LangGraph](https://langchain-ai.github.io/langgraph/).

---

## üìñ Table of Contents

- [What is LangGraph?](#-what-is-langgraph)
- [Why LangGraph?](#-why-langgraph)
- [Key Definitions](#-key-definitions)
- [LLM Workflows](#-llm-workflows)
- [Graphs, Nodes & Edges](#-graphs-nodes--edges)
- [State](#-state)
- [Project Structure](#-project-structure)
- [What We Built](#-what-we-built)
- [Tech Stack](#-tech-stack)
- [Prerequisites](#-prerequisites)
- [Installation & Setup](#-installation--setup)
- [How to Run](#-how-to-run)
- [Example Graph Flow](#-example-graph-flow)
- [Common Errors & Fixes](#-common-errors--fixes)
- [Interview Preparation](#-interview-preparation)
- [Resources](#-resources)

---

## ü§î What is LangGraph?

**LangGraph** is an orchestration framework for building intelligent, stateful, and multi-step LLM workflows. Instead of chaining prompts in a simple linear sequence, LangGraph lets you model your logic as a **graph of nodes (tasks) and edges (routing)**.

It enables advanced features like:
- ‚ö° **Parallelism** ‚Äî Run multiple tasks at the same time
- üîÅ **Loops** ‚Äî Retry or iterate until a condition is met
- üîÄ **Branching** ‚Äî Route to different nodes based on conditions
- üß† **Memory** ‚Äî Persist state across conversations
- ‚è∏Ô∏è **Resumability** ‚Äî Pause and resume workflows

This makes it ideal for **agentic** and **production-grade AI applications**.

---

## üí° Why LangGraph?

| Feature | Simple Chain | LangGraph |
|---------|-------------|-----------|
| Linear execution | ‚úÖ | ‚úÖ |
| Parallel execution | ‚ùå | ‚úÖ |
| Conditional routing | ‚ùå | ‚úÖ |
| Loops & retries | ‚ùå | ‚úÖ |
| State management | ‚ùå | ‚úÖ |
| Conversation memory | ‚ùå | ‚úÖ |
| Production-ready | ‚ùå | ‚úÖ |

---

## üìö Key Definitions

### üîπ LLM (Large Language Model)
A Large Language Model is a type of AI model trained on massive amounts of text data. It can understand and generate human-like text. Examples: GPT-4, Llama 3, Gemini, Claude.

### üîπ LangChain
LangChain is a Python framework for building applications powered by LLMs. It provides tools for prompts, chains, memory, tools, and agents. LangGraph is built on top of LangChain.

### üîπ Groq
Groq is an AI inference company that provides ultra-fast LLM API access. We use their API to run the `llama-3.3-70b-versatile` model in this project.

### üîπ Pydantic
Pydantic is a data validation library for Python. We use Pydantic `BaseModel` to define structured output schemas ‚Äî forcing the LLM to return data in a specific format (e.g., `feedback: str`, `score: int`).

### üîπ StateGraph
The main class in LangGraph. You define your state type, add nodes (functions), connect them with edges, and compile the graph into a runnable application.

### üîπ Checkpointer (MemorySaver)
A checkpointer saves the state of the graph after each node execution. `MemorySaver` is an in-memory checkpointer ‚Äî it enables conversation memory (multi-turn chat) by persisting state between invocations.

---

## üîÑ LLM Workflows

LLM workflows are a step-by-step process using which we can build complex LLM applications or a series of tasks to achieve a goal.

Each step in a workflow performs a distinct task ‚Äî such as prompting, reasoning, tool calling, memory access, or decision-making.

Workflows can be **linear**, **parallel**, **branched**, or **looped**.

### Common Workflow Patterns

#### 1. üîó Prompt Chaining
- **What**: Breaking a complex task into a sequence of simpler prompts where each prompt uses the previous prompt's output as input.
- **How**: Solve one subtask at a time ‚Üí pass its result to the next prompt ‚Üí compose final output from intermediate results.
- **Why**: Improves reliability, control, and traceability for complex requests.
- **Example in this project**: `Sequential Workflow 2.py` ‚Äî Generate outline ‚Üí Write draft ‚Üí Polish & summarize.

#### 2. üö¶ Routing
- **What**: Direct each incoming task/request to the correct handler or service based on rules, metadata, or content.
- **How**: Incoming message ‚Üí identify intent ‚Üí route to the right handler ‚Üí return response.
- **Why**: Different types of inputs often need different processing logic.

#### 3. ‚ö° Parallelization
- **What**: Run multiple independent LLM calls or tasks **at the same time** to reduce latency and increase throughput.
- **How**: For a given task, break it into multiple subtasks, execute all subtasks concurrently, and then merge their results.
- **Why**: When tasks are independent of each other, running them in parallel is significantly faster.
- **Example in this project**: `Parallel Workflow 2.py` ‚Äî Evaluate language, analysis, and clarity simultaneously.

#### 4. üéØ Orchestrator Workers
- **What**: Components that schedule, execute, and monitor workflow nodes, coordinating concurrent runs, retries, and state transitions.
- **How**: Orchestrator dispatches workers ‚Üí each worker runs a task ‚Üí reports results back ‚Üí orchestrator merges and advances.
- **Why**: Enables scalable, fault-tolerant workflow execution.

#### 5. üìä Evaluator Optimizer
- **What**: A component that scores, ranks, and selects candidate outputs to produce the best final result.
- **How**: Generate multiple candidate responses ‚Üí score each using metrics ‚Üí choose or ensemble the best.
- **Why**: Improves output quality by selecting from multiple attempts.

---

## üèóÔ∏è Graphs, Nodes & Edges

### 1. Graph
A **Graph** is the overarching structure that maps out how different tasks (nodes) are connected and executed. It visually represents the workflow, showing the sequence and conditional paths between various operations.

> üó∫Ô∏è **Analogy**: A road map displaying different routes connecting cities, with intersections offering choices on which path to take next.

### 2. Node
**Nodes** are individual functions or operations that perform specific tasks within the graph. Each node receives input (the current state), processes it, and produces an output (updated state).

> üè≠ **Analogy**: Assembly line stations ‚Äî each station does one job: attach a part, paint it, inspect quality, and so on.

**Important Rules:**
- Every node function receives the current state as input.
- Every node function **must return a `dict`** (partial state update) ‚Äî never return raw values like `float` or `str`.
- Nodes can contain any Python logic ‚Äî LLM calls, computations, API calls, etc.

### 3. Edges
**Edges** are the connections between nodes that determine the flow of execution. They tell us which node should be executed next after the current one completes.

> üõ§Ô∏è **Analogy**: Train tracks connecting stations together in a specific direction.

**Types of Edges:**
```python
# Normal edge ‚Äî A always goes to B
graph.add_edge('node_a', 'node_b')

# Fan-out ‚Äî START goes to multiple nodes (parallel execution)
graph.add_edge(START, 'node_a')
graph.add_edge(START, 'node_b')
graph.add_edge(START, 'node_c')

# Fan-in ‚Äî Multiple nodes go to one aggregator
graph.add_edge('node_a', 'aggregator')
graph.add_edge('node_b', 'aggregator')
graph.add_edge('node_c', 'aggregator')
```

---

## üì¶ State

The **State** is a shared data structure that holds the current information or context of the entire application. In simple terms, it is the application's memory ‚Äî keeping track of variables and data that nodes can access and modify as they execute.

> üìã **Analogy**: A whiteboard in a meeting room ‚Äî participants (nodes) write and read information on the whiteboard (state) to stay updated and coordinate actions.

### Defining State

State is typically defined using Python's `TypedDict`:

```python
from typing import TypedDict

class MyState(TypedDict):
    query: str
    response: str
    score: float
```

### State Reducers (for Parallel Workflows)

When multiple parallel nodes write to the same state key, you need a **reducer** to define how to combine the values:

```python
from typing import Annotated, List
import operator

class MyState(TypedDict):
    # operator.add means: APPEND to the list instead of replacing
    scores: Annotated[List[int], operator.add]
```

Without a reducer, the last node to finish would overwrite the value from previous nodes.

---

## üìÇ Project Structure

```
LangGraph/
‚îú‚îÄ‚îÄ üìÑ README.md                    ‚Üê You are here
‚îú‚îÄ‚îÄ üìÑ requirements.txt             ‚Üê Python dependencies
‚îú‚îÄ‚îÄ üìÑ .env                         ‚Üê Environment variables (GROQ_API_KEY)
‚îú‚îÄ‚îÄ üìÑ .gitignore                   ‚Üê Git ignore rules
‚îÇ
‚îú‚îÄ‚îÄ üìÅ Basic Bot/
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ ChatBot.py               ‚Üê Interactive chatbot with memory
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ README.md                ‚Üê Docs for this section
‚îÇ
‚îú‚îÄ‚îÄ üìÅ Sequential Workflow/
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ Sequential Workflow 1.py ‚Üê Simple single-node LLM query
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ Sequential Workflow.py   ‚Üê BMI Calculator (2 nodes)
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ Sequential Workflow 2.py ‚Üê Blog Post Generator (prompt chaining, 3 nodes)
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ README.md                ‚Üê Docs for this section
‚îÇ
‚îú‚îÄ‚îÄ üìÅ Parallel Workflow/
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ Parallel Workflow.py     ‚Üê Cricket Player Stats (3 parallel nodes)
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ Parallel Workflow 1.py   ‚Üê Structured LLM Output with Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ Parallel Workflow 2.py   ‚Üê UPSE Essay Evaluator (parallel LLM evaluation)
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ README.md                ‚Üê Docs for this section
‚îÇ
‚îú‚îÄ‚îÄ üìÅ Conditional Workflow/
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ Conditional Workflow.py   ‚Üê Quadratic Equation Solver (discriminant routing)
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ Conditional Workflow 1.py ‚Üê Voter Eligibility Checker (multi-step validation)
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ Conditional Workflow 2.py ‚Üê Medical Report Analyzer (LLM sentiment routing)
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ README.md                ‚Üê Docs for this section
‚îÇ
‚îú‚îÄ‚îÄ üìÑ Persistence.ipynb             ‚Üê Persistence & Checkpointing (notebook)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ Streamlit/
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ STM Bot.py/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ Bot.py               ‚Üê LangGraph backend (graph + checkpointer)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ app.py               ‚Üê Streamlit chat UI (frontend)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ README.md            ‚Üê Docs for this section
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ Streaming/
‚îÇ       ‚îú‚îÄ‚îÄ üìÑ Bot.py               ‚Üê LangGraph backend (same graph)
‚îÇ       ‚îú‚îÄ‚îÄ üìÑ app.py               ‚Üê Streamlit UI with token streaming
‚îÇ       ‚îî‚îÄ‚îÄ üìÑ README.md            ‚Üê Docs for this section
‚îÇ
‚îú‚îÄ‚îÄ üìÅ Interview Prep/
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ README.md                ‚Üê Interview prep guide & navigation
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ 01_MCQ.md                ‚Üê 55+ multiple-choice questions
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ 02_QnA.md                ‚Üê 55+ Q&A explanations
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ 03_Coding_Exercises.md   ‚Üê 13+ hands-on coding problems
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ 04_Scenario_Based.md     ‚Üê 15+ real-world scenarios
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ 05_Cheat_Sheet.md        ‚Üê Quick-reference cheat sheet
‚îÇ
‚îî‚îÄ‚îÄ üìÅ langvenv/                    ‚Üê Python virtual environment
```

---

## üèÜ What We Built

### Module 1: Basic Bot ‚Äî [`Basic Bot/`](./Basic%20Bot/)
An interactive **chatbot with conversation memory**. Uses `MemorySaver` checkpointer to remember previous messages across turns. Runs in a loop ‚Äî type messages and get AI responses.

### Module 2: Sequential Workflow ‚Äî [`Sequential Workflow/`](./Sequential%20Workflow/)
Three examples of **sequential (linear) workflows** where nodes execute one after another:
1. **Simple LLM Query** ‚Äî Single node that sends a query to the LLM.
2. **BMI Calculator** ‚Äî Two nodes: calculate BMI ‚Üí label the category. Pure computation, no LLM.
3. **Blog Post Generator** ‚Äî Three-step **prompt chaining**: generate outline ‚Üí write draft ‚Üí polish & summarize.

### Module 3: Parallel Workflow ‚Äî [`Parallel Workflow/`](./Parallel%20Workflow/)
Three examples of **parallel execution** where multiple nodes run simultaneously:
1. **Cricket Player Stats** ‚Äî Three stats computed in parallel, then summarized.
2. **Structured LLM Output** ‚Äî Using Pydantic `BaseModel` to force the LLM to return typed data.
3. **UPSE Essay Evaluator** ‚Äî Three LLM evaluators run in parallel (language, analysis, clarity), then an aggregator produces the overall score.

### Module 4: Conditional Workflow ‚Äî [`Conditional Workflow/`](./Conditional%20Workflow/)
Three examples of **conditional routing** where the next node is chosen at runtime based on the current state:
1. **Quadratic Equation Solver** ‚Äî Routes based on discriminant value (D > 0 / D = 0 / D < 0). Pure math, no LLM.
2. **Voter Eligibility Checker** ‚Äî Multi-step conditional validation (age ‚Üí citizenship ‚Üí criminal record) with early exit on failure.
3. **Medical Report Analyzer** ‚Äî LLM classifies report sentiment, then routes to positive/negative/neutral response handlers with structured output.

### Module 5: Persistence & Checkpointing ‚Äî [`Persistence.ipynb`](./Persistence.ipynb)
A Jupyter notebook exploring **how LangGraph saves and restores state** across invocations. Covers:
1. **Joke Generator with Checkpointing** ‚Äî A 2-node graph (`generate_joke` ‚Üí `explain_joke`) compiled with `InMemorySaver`.
2. **State Inspection** ‚Äî Using `get_state()` and `get_state_history()` to view all checkpoints.
3. **Short-Term Memory Chatbot** ‚Äî `add_messages` reducer + checkpointing for conversation memory.
4. **Fault Tolerance** ‚Äî Simulating a crash and resuming from the last successful checkpoint.
5. **Time Travel** ‚Äî Going back to a previous checkpoint and re-running from there.
6. **Updating State** ‚Äî Manually modifying state at a specific checkpoint with `update_state()`.

### Module 6: Streamlit STM Bot ‚Äî [`Streamlit/STM Bot.py/`](./Streamlit/STM%20Bot.py/)
A **web-based chat UI** built with Streamlit that brings the Short-Term Memory chatbot to life:
- **`Bot.py`** ‚Äî LangGraph backend: defines the graph, state, chat node, and compiles with `MemorySaver`.
- **`app.py`** ‚Äî Streamlit frontend: polished chat interface with gradient sidebar, thread switching, persistent history, and custom CSS.
- Supports **multiple conversation threads** ‚Äî switch between them without losing history.

### Module 7: Streaming Chat Bot ‚Äî [`Streamlit/Streaming/`](./Streamlit/Streaming/)
Builds on Module 6 by adding **real-time token-by-token streaming** ‚Äî text appears word by word like ChatGPT:
- Uses `app.stream(stream_mode="messages")` instead of `app.invoke()` for token-level output.
- A **Python generator** (`yield`) feeds tokens one at a time to `st.write_stream()` for instant display.
- Memory still works ‚Äî LangGraph auto-saves the checkpoint after streaming completes.

### Module 8: Interview Preparation ‚Äî [`Interview Prep/`](./Interview%20Prep/)
A **comprehensive, one-stop interview preparation guide** covering LangGraph from basic to advanced:
- **55+ MCQs** with hidden answers across 3 difficulty levels
- **55+ Q&A explanations** with code examples and in-depth analysis
- **13+ coding exercises** with full runnable solutions
- **15+ real-world scenarios** ‚Äî system design, debugging, architecture decisions
- **Quick-reference cheat sheet** for last-minute revision

---

## üõ†Ô∏è Tech Stack

| Technology | Purpose |
|------------|---------|
| [Python 3.10+](https://www.python.org/) | Programming language |
| [LangGraph](https://langchain-ai.github.io/langgraph/) | Graph-based workflow orchestration |
| [LangChain](https://www.langchain.com/) | LLM framework (core, messages, tools) |
| [LangChain-Groq](https://python.langchain.com/docs/integrations/chat/groq/) | Groq LLM integration for LangChain |
| [Groq API](https://console.groq.com/) | Ultra-fast LLM inference (Llama 3.3 70B) |
| [Pydantic](https://docs.pydantic.dev/) | Data validation & structured output |
| [python-dotenv](https://pypi.org/project/python-dotenv/) | Load environment variables from `.env` file |
| [Streamlit](https://streamlit.io/) | Web UI for the chatbot |

---

## ‚úÖ Prerequisites

Before you begin, make sure you have:

1. **Python 3.10 or higher** installed on your machine.
   ```bash
   python --version
   ```

2. **A Groq API Key** ‚Äî Sign up for free at [console.groq.com](https://console.groq.com/) and create an API key.

3. **Git** (optional) ‚Äî For cloning and version control.

---

## üöÄ Installation & Setup

### Step 1: Clone the Repository

```bash
git clone <your-repo-url>
cd LangGraph
```

### Step 2: Create a Virtual Environment

```bash
python -m venv langvenv
```

### Step 3: Activate the Virtual Environment

**Windows (PowerShell):**
```powershell
.\langvenv\Scripts\Activate.ps1
```

**Windows (Command Prompt):**
```cmd
.\langvenv\Scripts\activate.bat
```

**Linux / macOS:**
```bash
source langvenv/bin/activate
```

### Step 4: Install Dependencies

```bash
pip install -r requirements.txt
```

This will install:
- `langchain` ‚Äî Core LangChain framework
- `langchain-core` ‚Äî Core abstractions (messages, prompts)
- `langchain-community` ‚Äî Community integrations
- `langchain-groq` ‚Äî Groq LLM integration
- `python-dotenv` ‚Äî Environment variable management
- `langgraph` ‚Äî Graph-based workflow orchestration
- `pydantic` ‚Äî Data validation for structured output
- `streamlit` ‚Äî Web UI framework for the chatbot

### Step 5: Configure Environment Variables

Create a `.env` file in the root directory:

```env
GROQ_API_KEY=your_groq_api_key_here
```

> ‚ö†Ô∏è **Never commit your `.env` file to Git.** Make sure it's listed in `.gitignore`.

---

## ‚ñ∂Ô∏è How to Run

### 1. Activate the Virtual Environment

```powershell
.\langvenv\Scripts\Activate.ps1
```

### 2. Run Any Script

```bash
# Basic Bot ‚Äî Interactive chatbot
python "Basic Bot/ChatBot.py"

# Sequential Workflow ‚Äî Simple LLM query
python "Sequential Workflow/Sequential Workflow 1.py"

# Sequential Workflow ‚Äî BMI Calculator
python "Sequential Workflow/Sequential Workflow.py"

# Sequential Workflow ‚Äî Blog Post Generator (Prompt Chaining)
python "Sequential Workflow/Sequential Workflow 2.py"

# Parallel Workflow ‚Äî Cricket Player Stats
python "Parallel Workflow/Parallel Workflow.py"

# Parallel Workflow ‚Äî Structured LLM Output
python "Parallel Workflow/Parallel Workflow 1.py"

# Parallel Workflow ‚Äî UPSE Essay Evaluator
python "Parallel Workflow/Parallel Workflow 2.py"

# Conditional Workflow ‚Äî Quadratic Equation Solver
python "Conditional Workflow/Conditional Workflow.py"

# Conditional Workflow ‚Äî Voter Eligibility Checker
python "Conditional Workflow/Conditional Workflow 1.py"

# Conditional Workflow ‚Äî Medical Report Analyzer
python "Conditional Workflow/Conditional Workflow 2.py"

# Streamlit STM Bot ‚Äî Web chat UI
cd "Streamlit/STM Bot.py"
streamlit run app.py

# Streaming Chat Bot ‚Äî Real-time token streaming
cd "Streamlit/Streaming"
streamlit run app.py
```

---

## üó∫Ô∏è Example Graph Flow

### UPSC Essay Evaluation System (What We Are Building Towards)

The system generates an essay topic, collects the student's submission, and evaluates it in parallel on depth of analysis, language quality, and clarity of thought. Based on the combined score, it either gives feedback for improvement or approves the essay.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  GenerateTopic  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CollectEssay   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         EvaluateEssay (Parallel)            ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇEvaluateDepth ‚îÇ  ‚îÇ EvaluateLanguage  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ          ‚îÇ EvaluateClarity  ‚îÇ               ‚îÇ
‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚ñº
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ AggregateResults ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚ñº
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇConditionalRouting‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
              ‚ñº          ‚ñº
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇGiveFeedback‚îÇ  ‚îÇ ShowSuccess  ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚ñº
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇCollectRevision ‚îÇ ‚îÄ‚îÄ‚Üí (Loop back to EvaluateEssay)
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Steps:
1. **GenerateTopic** ‚Äî System generates a relevant UPSC-style essay topic.
2. **CollectEssay** ‚Äî Student writes and submits the essay.
3. **EvaluateEssay** (Parallel) ‚Äî Three evaluations run simultaneously:
   - **EvaluateDepth** ‚Äî Analyzes depth of analysis, argument strength, critical thinking.
   - **EvaluateLanguage** ‚Äî Checks grammar, vocabulary, fluency, and tone.
   - **EvaluateClarity** ‚Äî Assesses coherence, logical flow, and clarity of thought.
4. **AggregateResults** ‚Äî Combines scores and generates a total score.
5. **ConditionalRouting** ‚Äî Routes based on score:
   - Score meets threshold ‚Üí **ShowSuccess** ‚úÖ
   - Score below threshold ‚Üí **GiveFeedback** ‚ùå
6. **GiveFeedback** ‚Äî Provides targeted suggestions for improvement.
7. **CollectRevision** (optional loop) ‚Äî Student resubmits ‚Üí loop back to evaluation.
8. **ShowSuccess** ‚Äî Congratulates the student and ends the flow.

---

## ‚ö†Ô∏è Common Errors & Fixes

Here are the errors we encountered and fixed while building this project:

### 1. `ModuleNotFoundError: No module named 'langgraph'`
**Cause:** Dependencies not installed in the virtual environment.
**Fix:**
```bash
pip install -r requirements.txt
```

### 2. `InvalidUpdateError: Expected dict, got 2.0`
**Cause:** Node functions returning raw values (`float`, `str`) instead of dictionaries.
**Fix:** Always return a `dict` from node functions:
```python
# ‚ùå Wrong
def my_node(state):
    return 42

# ‚úÖ Correct
def my_node(state):
    return {'score': 42}
```

### 3. `TypeError: 'ResponseState' object is not subscriptable`
**Cause:** Using bracket notation on a Pydantic object.
**Fix:** Use dot notation for Pydantic objects:
```python
# ‚ùå Wrong
response['feedback']

# ‚úÖ Correct
response.feedback
```

### 4. `ImportError: cannot import name 'MemorySaver' from 'langgraph.graph.memory'`
**Cause:** Import path changed in newer versions of LangGraph.
**Fix:**
```python
# ‚ùå Old path
from langgraph.graph.memory import MemorySaver

# ‚úÖ New path
from langgraph.checkpoint.memory import MemorySaver
```

### 5. Using `{}` (set) instead of `[]` (list) for prompt messages
**Cause:** Sets are unordered and not valid input for LLM invocation.
**Fix:**
```python
# ‚ùå Wrong ‚Äî this creates a set (unordered!)
prompt = {
    SystemMessage(content="..."),
    HumanMessage(content="...")
}

# ‚úÖ Correct ‚Äî this creates a list (ordered)
prompt = [
    SystemMessage(content="..."),
    HumanMessage(content="...")
]
```

### 6. `NameError: name 'Field' is not defined`
**Cause:** Using `Field()` without importing it from Pydantic.
**Fix:**
```python
from pydantic import BaseModel, Field
```

---

## üìö Resources

- üìò [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- üìò [LangChain Documentation](https://python.langchain.com/docs/)
- üìò [Groq Console](https://console.groq.com/)
- üìò [Pydantic Documentation](https://docs.pydantic.dev/)
- üìò [LangGraph GitHub](https://github.com/langchain-ai/langgraph)

---

## üìù License

This is a personal learning project. Feel free to use it for your own learning!

---

> Built with ‚ù§Ô∏è using LangGraph + Groq + LangChain
